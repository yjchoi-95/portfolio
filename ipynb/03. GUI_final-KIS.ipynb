{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43390c19-3fa4-4b30-b76c-704f7d8816f3",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b6e3f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python2\\python-3.8.9.amd64\\lib\\site-packages\\pyfolio\\pos.py:26: UserWarning: Module \"zipline.assets\" not found; mutltipliers will not be applied to position notionals.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: Could not locate executable g77\n",
      "WARN: Could not locate executable f77\n",
      "WARN: Could not locate executable ifort\n",
      "WARN: Could not locate executable ifl\n",
      "WARN: Could not locate executable f90\n",
      "WARN: Could not locate executable DF\n",
      "WARN: Could not locate executable efl\n",
      "WARN: Could not locate executable gfortran\n",
      "WARN: Could not locate executable f95\n",
      "WARN: Could not locate executable g95\n",
      "WARN: Could not locate executable efort\n",
      "WARN: Could not locate executable efc\n",
      "WARN: Could not locate executable flang\n",
      "WARN: don't know how to compile Fortran code on platform 'nt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.configdefaults): g++ not available, if using conda: `conda install m2w64-toolchain`\n",
      "WARNING (theano.configdefaults): g++ not detected ! Theano will be unable to execute optimized C-implementations (for both CPU and GPU) and will default to Python implementations. Performance will be severely degraded. To remove this warning, set Theano flags cxx to an empty string.\n",
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "from pypfopt.expected_returns import mean_historical_return, ema_historical_return, capm_return, returns_from_prices\n",
    "from pypfopt.risk_models import CovarianceShrinkage\n",
    "from pypfopt.cla import CLA\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models, exceptions\n",
    "from pypfopt import EfficientFrontier, CLA\n",
    "from mdutils.mdutils import MdUtils\n",
    "from mdutils.tools.Table import Table\n",
    "from tkinter import * # __all__\n",
    "from tkinter import filedialog\n",
    "from time import gmtime, strftime, localtime\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta, datetime\n",
    "from collections import OrderedDict\n",
    "from pyfolio.utils import APPROX_BDAYS_PER_MONTH, MM_DISPLAY_UNIT\n",
    "from pypfopt.cla import CLA\n",
    "\n",
    "import tkinter.ttk as ttk\n",
    "import tkinter.messagebox as msgbox\n",
    "import matplotlib.pyplot as plt\n",
    "import xlwings as xw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import FinanceDataReader as fdr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyfolio as pf\n",
    "import seaborn as sns\n",
    "import pypfopt\n",
    "import empyrical\n",
    "import markdown\n",
    "import os, re, copy, warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "plt.style.use(\"seaborn-deep\")\n",
    "plt.rcParams['font.family']= \"gulim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aeed64-7c2c-4414-88fe-4ce48724b815",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7447ba8e",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273d2fe1",
   "metadata": {},
   "source": [
    "* about data crwaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b38e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_xlsx(name):\n",
    "    instance = xw.App(visible = False)\n",
    "    xlsx_data = xw.Book(name).sheets[0]\n",
    "    df = xlsx_data.range('A1').options(pd.DataFrame, index = False, expand = 'table').value\n",
    "    instance.quit()\n",
    "    instance.kill()\n",
    "    return df\n",
    "\n",
    "def read_data(name):\n",
    "    try :\n",
    "        output = pd.read_excel(name)\n",
    "    except ValueError:    \n",
    "        output = read_xlsx(name)\n",
    "    return output\n",
    "\n",
    "def get_stock_list(data_path):\n",
    "    if os.path.isfile(data_path + \"df_krx.xlsx\") & os.path.isfile(data_path + \"df_america.xlsx\"):\n",
    "        df_krx = read_data(data_path + \"df_krx.xlsx\")\n",
    "        df_america = read_data(data_path + \"df_america.xlsx\")\n",
    "        \n",
    "    else:\n",
    "        df_krx = fdr.StockListing('KRX')\n",
    "        df_sp500 = fdr.StockListing('S&P500')\n",
    "        df_nas = fdr.StockListing('NASDAQ')\n",
    "        df_nyse = fdr.StockListing('NYSE')\n",
    "        df_amex = fdr.StockListing('AMEX')\n",
    "\n",
    "        df_america = pd.concat([df_nas, df_nyse, df_amex]).drop_duplicates()\n",
    "        append_code = [x for x in df_sp500.Symbol if x not in list(df_america.Symbol)]\n",
    "        append_df = df_sp500.loc[df_sp500.Symbol.isin(append_code)]\n",
    "        del append_df['Sector']\n",
    "        df_america = pd.concat([df_america, append_df])\n",
    "        df_america.index = [x for x in range(df_america.shape[0])]\n",
    "        \n",
    "        df_krx.to_excel(data_path + \"df_krx.xlsx\", index = False)\n",
    "        df_america.to_excel(data_path + \"df_america.xlsx\", index = False)\n",
    "    \n",
    "    return df_krx, df_america\n",
    "\n",
    "def change_name(symbol, df, options):\n",
    "    if options:\n",
    "        output = df.loc[df.Symbol == symbol, 'Name'].values[0]\n",
    "    else:\n",
    "        output = df.loc[df['상품번호'] == symbol, '종목명'].values[0]\n",
    "    return output\n",
    "\n",
    "def make_df(name, df):\n",
    "    temp_df = pd.DataFrame(df.Close)\n",
    "    temp_df.columns = ['{}'.format(name)]\n",
    "    return temp_df.reset_index()\n",
    "\n",
    "def get_currency(data_path):\n",
    "    # 환율 가져오기\n",
    "    if os.path.isfile(data_path + \"currency.xlsx\"):\n",
    "        currency = read_data(data_path + \"currency.xlsx\")\n",
    "\n",
    "    start_date = np.max(currency.Date)\n",
    "\n",
    "    try :\n",
    "        append_curr = fdr.DataReader(\"USD/KRW\", start = start_date)\n",
    "        append_curr = append_curr.reset_index()\n",
    "\n",
    "        currency = currency.loc[currency.Date < start_date, :]\n",
    "        currency = pd.concat([currency, append_curr])\n",
    "        currency.index = [x for x in range(currency.shape[0])]\n",
    "        currency.to_excel(data_path + \"currency.xlsx\", index = False)\n",
    "\n",
    "    except:\n",
    "        print(\"추가행 없음\")\n",
    "        pass\n",
    "    return currency, start_date\n",
    "\n",
    "def load_data(data_path):\n",
    "    # data 불러오기\n",
    "    if os.path.isfile(data_path + \"df_infos.xlsx\"):\n",
    "        df_infos = read_data(data_path + \"df_infos.xlsx\")\n",
    "        df_krx, df_america = get_stock_list(data_path)\n",
    "        df_america = df_america.loc[:, ['Symbol', 'Name']]\n",
    "        df_krx = df_krx.loc[:, ['Symbol', 'Name']]\n",
    "        \n",
    "    else:\n",
    "        df_krx, df_america = get_stock_list(data_path)\n",
    "        df_america = df_america.loc[:, ['Symbol', 'Name']]\n",
    "        df_krx = df_krx.loc[:, ['Symbol', 'Name']]\n",
    "        df_infos = pd.concat([df_krx, df_america])\n",
    "        df_infos = df_infos.dropna()\n",
    "        df_infos.index = [x for x in range(df_infos.shape[0])]\n",
    "\n",
    "        symbol_list = []\n",
    "\n",
    "        for symbol, name in zip(df_infos.Symbol, df_infos.Name):\n",
    "            if \" PR \" in symbol:\n",
    "                symbol_list.append(re.sub(\" PR \",\"/\",symbol))\n",
    "            elif (\".U\" in symbol) and (\"Units\" in name):\n",
    "                symbol_list.append(re.sub(\".U\",\"/UN\",symbol))\n",
    "            elif \"\\.\" in symbol:\n",
    "                symbol_list.append(re.sub(\"\\.\", \"/\", symbol))\n",
    "            elif \" RT\" in symbol:\n",
    "                symbol_list.append(symbol.split(\" \")[0])\n",
    "            elif symbol == 'BRKB':\n",
    "                symbol_list.append(\"BRK/B\")\n",
    "            elif symbol == 'BFB':\n",
    "                symbol_list.append(\"BF/B\")\n",
    "            else:\n",
    "                symbol_list.append(symbol)\n",
    "\n",
    "        df_infos['WINK_symbols'] = symbol_list\n",
    "        df_infos.to_excel(data_path + \"df_infos.xlsx\", index = False)\n",
    "    return df_infos\n",
    "\n",
    "def get_include_data(data, df_infos, currency, data_path, min_date):\n",
    "    if '계좌번호' in list(data.columns):\n",
    "        cate_list = ['주식', 'NYSE', 'AMEX', 'NASD']\n",
    "\n",
    "        data = data.loc[data['상품구분'].isin(cate_list)]\n",
    "        account = [True if \"-01\" in x else False for x in data['계좌번호']]\n",
    "        data = data.loc[account, :]\n",
    "\n",
    "        # 국내 주식\n",
    "        stock_list = data.loc[data['상품구분'] == '주식']['종목명']\n",
    "        symbol_list = list(df_infos.loc[df_infos.Name.isin(stock_list)].Symbol)\n",
    "        th = len(symbol_list)\n",
    "\n",
    "        # 미국 주식\n",
    "        stock_list = data.loc[data['상품구분'] != '주식']['상품번호']\n",
    "        symbol_list.extend(list(df_infos.loc[df_infos.Symbol.isin(stock_list)].Symbol))\n",
    "\n",
    "        start_idx = 0\n",
    "\n",
    "        for idx, symbol in enumerate(tqdm(symbol_list[start_idx:])):\n",
    "            if \" \" in symbol:\n",
    "                search_symbol = symbol\n",
    "                symbol = df_infos.loc[df_infos.Symbol == symbol, :].WINK_symbols.values[0]\n",
    "            else:\n",
    "                search_symbol = symbol\n",
    "\n",
    "            try:\n",
    "                df = fdr.DataReader(symbol, start = min_date)\n",
    "\n",
    "            except ValueError:\n",
    "                start_idx += 1\n",
    "                continue\n",
    "\n",
    "            if df.shape[0] == 0:\n",
    "                start_idx += 1\n",
    "                continue\n",
    "\n",
    "            if start_idx >= th:\n",
    "                name = change_name(search_symbol, data, False)\n",
    "            else:\n",
    "                name = change_name(search_symbol, df_infos, True)\n",
    "\n",
    "            if start_idx == 0 :\n",
    "                temp_stock_df = make_df(name, df)\n",
    "            else:\n",
    "                temp_df = make_df(name, df)\n",
    "                temp_stock_df = pd.merge(temp_stock_df, temp_df, on ='Date', how = 'outer')\n",
    "\n",
    "            start_idx += 1\n",
    "\n",
    "        temp_stock_df = temp_stock_df.sort_values(\"Date\")\n",
    "        temp_stock_df.index = [x for x in range(temp_stock_df.shape[0])]\n",
    "\n",
    "        # 한/미 증시 시차로 인한 NA 값 발생\n",
    "        if temp_stock_df.iloc[-1:].isna().sum().sum() > 0:\n",
    "            temp_stock_df = temp_stock_df.iloc[:-1,:]\n",
    "\n",
    "        # 미국 종목 환율 반영\n",
    "        select_col = [0]\n",
    "        select_col.extend([x for x in range(th+1, temp_stock_df.shape[1])])\n",
    "\n",
    "        temp_df = pd.merge(temp_stock_df.iloc[:, select_col], currency.loc[:, ['Date', 'Close']], on = 'Date', how = 'inner')\n",
    "        stock_df = temp_stock_df.iloc[:, :(th+1)]\n",
    "\n",
    "        def exchange(x):\n",
    "            return x * temp_df['Close']\n",
    "\n",
    "        temp_df.iloc[:, 1:-1] = temp_df.iloc[:, 1:-1].apply(exchange, axis = 0)\n",
    "        stock_df = pd.merge(stock_df, temp_df, on = 'Date', how = 'inner')\n",
    "        del stock_df['Close']\n",
    "\n",
    "        stock_df.to_excel(data_path + \"stock_df.xlsx\", index = False)\n",
    "\n",
    "    else:\n",
    "        data = data.iloc[1:, :]\n",
    "\n",
    "        stock_list = data['종목명']\n",
    "        symbol_list = list(df_infos.loc[df_infos.Name.isin(stock_list)].Symbol)\n",
    "\n",
    "        start_idx = 0\n",
    "\n",
    "        for idx, symbol in enumerate(tqdm(symbol_list[start_idx:])):\n",
    "            try:\n",
    "                df = fdr.DataReader(symbol, start = min_date)\n",
    "\n",
    "            except ValueError:\n",
    "                start_idx += 1\n",
    "                continue\n",
    "\n",
    "            if df.shape[0] == 0:\n",
    "                start_idx += 1\n",
    "                continue\n",
    "\n",
    "            name = change_name(symbol, df_infos, True)\n",
    "\n",
    "            if start_idx == 0 :\n",
    "                stock_df = make_df(name, df)\n",
    "            else:\n",
    "                temp_df = make_df(name, df)\n",
    "                stock_df = pd.merge(stock_df, temp_df, on ='Date', how = 'outer')\n",
    "\n",
    "            start_idx += 1\n",
    "\n",
    "        stock_df = stock_df.sort_values(\"Date\")\n",
    "        stock_df.index = [x for x in range(stock_df.shape[0])]\n",
    "\n",
    "        stock_df.to_excel(data_path + \"stock_df.xlsx\", index = False)\n",
    "    return stock_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f477510",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7271619",
   "metadata": {},
   "source": [
    "* about portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1bd171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perf_stats(returns, factor_returns=None, positions=None,\n",
    "                    transactions=None, turnover_denom='AGB',\n",
    "                    live_start_date=None, bootstrap=False,\n",
    "                    header_rows=None):\n",
    "    if bootstrap:\n",
    "        perf_func = pf.timeseries.perf_stats_bootstrap\n",
    "    else:\n",
    "        perf_func = pf.timeseries.perf_stats\n",
    "    STAT_FUNCS_PCT = [\n",
    "        'Annual return',\n",
    "        'Cumulative returns',\n",
    "        'Annual volatility',\n",
    "        'Max drawdown',\n",
    "        'Daily value at risk',\n",
    "        'Daily turnover'\n",
    "    ]\n",
    "\n",
    "    perf_stats_all = perf_func(\n",
    "        returns,\n",
    "        factor_returns=factor_returns,\n",
    "        positions=positions,\n",
    "        transactions=transactions,\n",
    "        turnover_denom=turnover_denom)\n",
    "\n",
    "    date_rows = OrderedDict()\n",
    "    if len(returns.index) > 0:\n",
    "        date_rows['Start date'] = returns.index[0].strftime('%Y-%m-%d')\n",
    "        date_rows['End date'] = returns.index[-1].strftime('%Y-%m-%d')\n",
    "\n",
    "    if live_start_date is not None:\n",
    "        live_start_date = ep.utils.get_utc_timestamp(live_start_date)\n",
    "        returns_is = returns[returns.index < live_start_date]\n",
    "        returns_oos = returns[returns.index >= live_start_date]\n",
    "\n",
    "        positions_is = None\n",
    "        positions_oos = None\n",
    "        transactions_is = None\n",
    "        transactions_oos = None\n",
    "\n",
    "        if positions is not None:\n",
    "            positions_is = positions[positions.index < live_start_date]\n",
    "            positions_oos = positions[positions.index >= live_start_date]\n",
    "            if transactions is not None:\n",
    "                transactions_is = transactions[(transactions.index <\n",
    "                                                live_start_date)]\n",
    "                transactions_oos = transactions[(transactions.index >\n",
    "                                                 live_start_date)]\n",
    "\n",
    "        perf_stats_is = perf_func(\n",
    "            returns_is,\n",
    "            factor_returns=factor_returns,\n",
    "            positions=positions_is,\n",
    "            transactions=transactions_is,\n",
    "            turnover_denom=turnover_denom)\n",
    "\n",
    "        perf_stats_oos = perf_func(\n",
    "            returns_oos,\n",
    "            factor_returns=factor_returns,\n",
    "            positions=positions_oos,\n",
    "            transactions=transactions_oos,\n",
    "            turnover_denom=turnover_denom)\n",
    "        if len(returns.index) > 0:\n",
    "            date_rows['In-sample months'] = int(len(returns_is) /\n",
    "                                                APPROX_BDAYS_PER_MONTH)\n",
    "            date_rows['Out-of-sample months'] = int(len(returns_oos) /\n",
    "                                                    APPROX_BDAYS_PER_MONTH)\n",
    "\n",
    "        perf_stats = pd.concat(OrderedDict([\n",
    "            ('In-sample', perf_stats_is),\n",
    "            ('Out-of-sample', perf_stats_oos),\n",
    "            ('All', perf_stats_all),\n",
    "        ]), axis=1)\n",
    "    else:\n",
    "        if len(returns.index) > 0:\n",
    "            date_rows['Total months'] = int(len(returns) /\n",
    "                                            APPROX_BDAYS_PER_MONTH)\n",
    "        perf_stats = pd.DataFrame(perf_stats_all, columns=['Backtest'])\n",
    "\n",
    "    for column in perf_stats.columns:\n",
    "        for stat, value in perf_stats[column].iteritems():\n",
    "            if stat in STAT_FUNCS_PCT:\n",
    "                perf_stats.loc[stat, column] = str(np.round(value * 100,\n",
    "                                                            3)) + '%'\n",
    "    if header_rows is None:\n",
    "        header_rows = date_rows\n",
    "    else:\n",
    "        header_rows = OrderedDict(header_rows)\n",
    "        header_rows.update(date_rows)\n",
    "    return perf_stats\n",
    "\n",
    "def get_price(df, date, name):\n",
    "    while True :\n",
    "        if np.isnan(df.loc[df.Date == date, name].values[0]):\n",
    "            date -= pd.Timedelta(days = 1)\n",
    "            \n",
    "            while True:\n",
    "                if date not in list(df.Date):\n",
    "                    date -= pd.Timedelta(days = 1)\n",
    "                else:\n",
    "                    break\n",
    "        else:\n",
    "            break\n",
    "    return df.loc[df.Date == date, name].values[0]\n",
    "\n",
    "## change에 따른 자산 변화\n",
    "def cal_changes(initial_value, df, col):\n",
    "    change_values = [initial_value]\n",
    "    \n",
    "    cnt = 0\n",
    "    for pct in df.loc[:, col]:\n",
    "        if np.isnan(pct):\n",
    "            pct = 0\n",
    "        change_values.append(change_values[cnt] + change_values[cnt] * pct)\n",
    "        cnt += 1\n",
    "    return change_values\n",
    "\n",
    "def get_return(port_input, opt = 'mean'):\n",
    "    if opt == 'mean':\n",
    "        output = mean_historical_return(port_input)\n",
    "    elif opt == 'ema':\n",
    "        output = ema_historical_return(port_input)\n",
    "    elif opt == 'capm':\n",
    "        output = capm_return(port_input)\n",
    "    elif opt == \"price\":\n",
    "        output = returns_from_prices(port_input)\n",
    "    return output\n",
    "\n",
    "def get_cov(port_input, opt = 'CovarianceShrinkage-01'):\n",
    "    if opt == 'CovarianceShrinkage-01':\n",
    "        S = CovarianceShrinkage(port_input).ledoit_wolf()\n",
    "    elif opt == 'CovarianceShrinkage-02':\n",
    "        S = CovarianceShrinkage(port_input).shrunk_covariance()\n",
    "    elif opt == 'CovarianceShrinkage-03':\n",
    "        S = CovarianceShrinkage(port_input).oracle_approximating()\n",
    "    elif opt == \"exp_cov\":\n",
    "        S = pypfopt.risk_models.exp_cov(port_input)\n",
    "    elif opt == \"semicovariance\":\n",
    "        S = pypfopt.risk_models.semicovariance(port_input)\n",
    "    return S\n",
    "\n",
    "def mvo(ef, method = \"max_sharpe\"):\n",
    "    if method == 'max_sharpe':\n",
    "        weights = ef.max_sharpe()\n",
    "    elif method == \"min_volatility\":\n",
    "        weights = ef.min_volatility()\n",
    "    elif method == \"max_quadratic_utility\":\n",
    "        weights = ef.max_quadratic_utility()\n",
    "    return weights\n",
    "\n",
    "def obj_functions(ef, label):\n",
    "    if label == \"Max Sharpe\":\n",
    "        return ef.max_sharpe()\n",
    "    elif label == \"Min Volatility\":\n",
    "        return ef.min_volatility()\n",
    "\n",
    "def plot_pie(weights_df, save_img_path, inches = (12, 8)):\n",
    "    fig, ax = plt.subplots(figsize=(32, 32), subplot_kw=dict(aspect=\"equal\"))\n",
    "    data = list(weights_df.allocations)\n",
    "    ingredients = list(weights_df.index)\n",
    "\n",
    "    def func(pct, allvals):\n",
    "        absolute = int(pct/100.*np.sum(allvals))\n",
    "        return \"{:.1f}%\".format(pct)\n",
    "\n",
    "    wedges, texts, autotexts = ax.pie(data, autopct=lambda pct: func(pct, data),\n",
    "                                      textprops=dict(color=\"w\"))\n",
    "    ax.legend(wedges, ingredients,\n",
    "              title=\"Stocks\",\n",
    "              loc=\"center left\",\n",
    "              bbox_to_anchor=(1, 0, 0.5, 1))\n",
    "    plt.setp(autotexts, size=13, weight=\"bold\")\n",
    "    ax.set_title(\"Portfolio Allocations\", size = 15)\n",
    "    plt.gcf().set_size_inches(inches)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_img_path + 'Portfolio Allocations.png', facecolor='#eeeeee', edgecolor='black')\n",
    "    plt.close()\n",
    "\n",
    "def plot_abount_returns(returns, positions, bench_rets, save_img_path, bench_name, inches = (12, 8)):\n",
    "    ## rolling returns\n",
    "    pf.plot_rolling_returns(returns=returns.loc[returns.index.isin(bench_rets.index)], \n",
    "                        factor_returns=bench_rets.pct_change(),\n",
    "                        live_start_date=pd.Timestamp('2022-07-01'),\n",
    "                        cone_std = [1.0, 1.5, 2.0])\n",
    "    plt.gcf().set_size_inches(inches)\n",
    "    plt.title(\"Portfolio Growth\", size = 15)\n",
    "    plt.savefig(save_img_path + 'Portfolio Growth.png',facecolor='#eeeeee')\n",
    "    plt.close()\n",
    "    \n",
    "    ## RETURNS\n",
    "    pf.plot_returns(returns)\n",
    "    plt.gcf().set_size_inches(inches)\n",
    "    plt.title(\"Returns\", size = 15)\n",
    "    plt.savefig(save_img_path + 'Returns.png', facecolor='#eeeeee')\n",
    "    plt.close()\n",
    "    \n",
    "    ## return and groth\n",
    "    fig, ax = plt.subplots(nrows = 2, ncols=1, figsize = (12, 16))\n",
    "    axes = ax.flatten()\n",
    "    pf.plot_rolling_returns(returns=returns.loc[returns.index.isin(bench_rets.index)], \n",
    "                            factor_returns=bench_rets.pct_change(),\n",
    "                            live_start_date=pd.Timestamp('2022-07-01'),\n",
    "                            cone_std = [1.0, 1.5, 2.0],\n",
    "                           ax = axes[0],\n",
    "                           title = \"Portfolio Growth\")\n",
    "    pf.plot_returns(returns, ax = axes[1])\n",
    "    plt.tight_layout()\n",
    "    plt.title(\"Return\")\n",
    "    plt.savefig(save_img_path + 'Growth & Return.png', facecolor='#eeeeee')\n",
    "    plt.close()\n",
    "\n",
    "    ## annual returns\n",
    "    pf.plot_annual_returns(returns)\n",
    "    plt.gcf().set_size_inches(inches)\n",
    "    plt.title(\"Annual Returns\", size = 15)\n",
    "    plt.legend([\"Return\"])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_img_path + 'Annual Returns.png', facecolor='#eeeeee')\n",
    "    plt.close()\n",
    "    \n",
    "    ## monthly returns\n",
    "    pf.plot_monthly_returns_heatmap(returns)\n",
    "    plt.gcf().set_size_inches(inches)\n",
    "    plt.title(\"Monthly Returns (%)\", size = 15)\n",
    "    plt.savefig(save_img_path + 'Monthly Returns (%).png', facecolor='#eeeeee')\n",
    "    plt.close()\n",
    "    \n",
    "    pf.plot_monthly_returns_timeseries(returns)\n",
    "    plt.gcf().set_size_inches(inches)\n",
    "    plt.title(\"Monthly Returns Timeseries\", size = 15)\n",
    "    plt.savefig(save_img_path + 'Monthly Returns Timeseries.png', facecolor='#eeeeee')\n",
    "    plt.close()\n",
    "    \n",
    "    pf.plot_monthly_returns_dist(returns)\n",
    "    plt.gcf().set_size_inches(inches)\n",
    "    plt.title(\"Distribution of Monthly Returns\", size = 15)\n",
    "    plt.legend([\"Return\"])\n",
    "    plt.savefig(save_img_path + 'Distribution of Monthly Returns.png', facecolor='#eeeeee')\n",
    "    plt.close()\n",
    "    \n",
    "    ## return and groth\n",
    "    fig, ax = plt.subplots(nrows = 2, ncols=2, figsize = (20, 12))\n",
    "    axes = ax.flatten()\n",
    "\n",
    "    pf.plot_annual_returns(returns, ax = axes[0])\n",
    "    plt.title(\"Annual Returns\")\n",
    "    plt.legend([\"Return\"])\n",
    "\n",
    "    pf.plot_monthly_returns_heatmap(returns, ax = axes[2])\n",
    "    plt.title(\"Monthly Returns (%)\")\n",
    "\n",
    "    pf.plot_monthly_returns_dist(returns, ax = axes[1])\n",
    "    plt.title(\"Distribution of Monthly Returns\")\n",
    "\n",
    "    pf.plot_monthly_returns_timeseries(returns, ax = axes[3])\n",
    "    plt.title(\"Monthly Returns Timeseries\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_img_path + 'Monthly & Annualy Returns.png', facecolor='#eeeeee')\n",
    "    plt.close()\n",
    "    \n",
    "    pf.plot_return_quantiles(returns)\n",
    "    plt.gcf().set_size_inches(inches)\n",
    "    plt.title(\"Returns Quantiles per Periods\", size = 15)\n",
    "    plt.savefig(save_img_path + 'Returns Quantiles per Periods.png', facecolor='#eeeeee')\n",
    "    plt.close()\n",
    "    \n",
    "    pf.plotting.plot_perf_stats(returns, None)\n",
    "    plt.gcf().set_size_inches(inches)\n",
    "    plt.savefig(save_img_path + 'Portfolio Summary.png', facecolor='#eeeeee')\n",
    "    plt.close()\n",
    "    \n",
    "    pf.plotting.plot_rolling_beta(returns, bench_rets.pct_change())\n",
    "    plt.gcf().set_size_inches(inches)\n",
    "    plt.ylim([-1, 1.5])\n",
    "    plt.title(\"Rolling Portfolio Beta to {}\".format(bench_name), size = 15)\n",
    "    plt.savefig(save_img_path + \"Rolling Portfolio Beta to {}.png\".format(bench_name),facecolor='#eeeeee')\n",
    "    plt.close()\n",
    "    \n",
    "    pf.plot_rolling_sharpe(returns)\n",
    "    plt.gcf().set_size_inches(inches)\n",
    "    plt.title(\"Rolling Sharpe Ratio (6-month)\", size = 15)\n",
    "    plt.savefig(save_img_path + 'Rolling Sharpe Ratio (6-month).png', facecolor='#eeeeee')\n",
    "    plt.close()\n",
    "    \n",
    "    pf.plot_drawdown_periods(returns,top = 5)\n",
    "    plt.gcf().set_size_inches(inches)\n",
    "    plt.title(\"Top 5 Drawdown Periods\", size = 15)\n",
    "    plt.savefig(save_img_path + 'Top 5 Drawdown Periods.png', facecolor='#eeeeee')\n",
    "    plt.close()\n",
    "    \n",
    "    pf.plot_drawdown_underwater(returns)\n",
    "    plt.gcf().set_size_inches(inches)\n",
    "    plt.title(\"Underwater Plot\", size = 15)\n",
    "    plt.savefig(save_img_path + 'Underwater Plot.png', facecolor='#eeeeee')\n",
    "    plt.close()\n",
    "    \n",
    "    ## total 4\n",
    "    fig, ax = plt.subplots(nrows = 2, ncols=2, figsize = (20, 12))\n",
    "    axes = ax.flatten()\n",
    "\n",
    "    pf.plot_drawdown_periods(returns, top = 5, ax = axes[0])\n",
    "    plt.title(\"Top 5 Drawdown Periods\", size = 15)\n",
    "\n",
    "    pf.plotting.plot_rolling_beta(returns, bench_rets.pct_change(), ax = axes[1], ylim = [-1, 1.5])\n",
    "    plt.title(\"Rolling Portfolio Beta to {}\".format(bench_name), size = 15)\n",
    "\n",
    "    pf.plot_drawdown_underwater(returns, ax = axes[2])\n",
    "    plt.title(\"Underwater Plot\", size = 15)\n",
    "\n",
    "    pf.plot_rolling_sharpe(returns, ax = axes[3])\n",
    "    plt.title(\"Rolling Sharpe Ratio (6-month)\", size = 15)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_img_path + 'Factor & Drawdown.png', facecolor='#eeeeee')\n",
    "    plt.close()\n",
    "    \n",
    "    pf.plotting.show_and_plot_top_positions(returns, positions, show_and_plot=0)\n",
    "    plt.gcf().set_size_inches(inches)\n",
    "    plt.title(\"Portfolio Allocation over Time, Only Top 10 Holdings\", size = 15)\n",
    "    plt.savefig(save_img_path + 'Portfolio Allocation over Time, Only Top 10 Holdings.png', facecolor='#eeeeee')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb849dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee9129d0",
   "metadata": {},
   "source": [
    "* about tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3e64576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 데이터 파일 추가\n",
    "def add_file():\n",
    "    files = filedialog.askopenfilenames(title=\"데이터 선택\", \\\n",
    "        filetypes=((\"모든 파일\", \"*.*\"),\n",
    "                (\"엑셀 파일\", \"*.xlsx\"),\n",
    "                (\"csv 파일\", \"*.csv\")),\\\n",
    "        initialdir=\"./datasets/\")\n",
    "    \n",
    "    for idx, file in enumerate(files):\n",
    "        list_file.insert(parent=\"\", index = \"end\", iid = idx,text = file, value = (END, file))\n",
    "        \n",
    "# 선택 삭제\n",
    "def del_file():\n",
    "    selected_item = list_file.selection()[0]\n",
    "    list_file.delete(selected_item)\n",
    "    \n",
    "# 저장 경로 (폴더)\n",
    "def browse_dest_path():\n",
    "    folder_selected = filedialog.askdirectory()\n",
    "    if folder_selected is None: # 사용자가 취소를 누를 때\n",
    "        return\n",
    "    txt_dest_path.delete(0, END)\n",
    "    txt_dest_path.insert(0, folder_selected)\n",
    "\n",
    "def read_xlsx(name):\n",
    "    instance = xw.App(visible=False)\n",
    "    xlsx_data = xw.Book(name).sheets[0]\n",
    "    df = xlsx_data.range('A1').options(pd.DataFrame, index = False, expand = 'table').value\n",
    "    instance.quit()\n",
    "    instance.kill()\n",
    "    return df\n",
    "\n",
    "# load data\n",
    "def main_functions():\n",
    "    global pf_year\n",
    "    complete = True\n",
    "    \n",
    "    ## 저장경로 에러\n",
    "    if balance_space.get() == \"\":\n",
    "        msgbox.showerror(\"에러\", \"초기 금액을 설정하세요.\")\n",
    "        complete = False\n",
    "        \n",
    "    else:\n",
    "        ## 01. data-include part\n",
    "        data_path = os.getcwd() + \"\\\\datasets\\\\\"\n",
    "        currency, _ = get_currency(data_path)\n",
    "        df_infos = load_data(data_path)\n",
    "        year = pf_year.get()\n",
    "        start_date = str(year) + \"-01-01\"\n",
    "        \n",
    "        ## load files\n",
    "        '''\n",
    "        datas = []\n",
    "        for parent in list_file.get_children():\n",
    "            datas.append(read_data(list_file.item(parent)[\"values\"][1]))\n",
    "\n",
    "        if len(datas) == 1:\n",
    "            data = datas[0]\n",
    "        '''\n",
    "        \n",
    "        data = read_data(\"./datasets/\" + data_space.get())\n",
    "        \n",
    "        stock_df = get_include_data(data, df_infos, currency, data_path, start_date)\n",
    "        port_input = stock_df.iloc[:, 1:]\n",
    "        #print(stock_df.shape) (8433, 25)\n",
    "        #print(port_input.shape) (8433, 24)\n",
    "        \n",
    "        rebalancing_days = {\"Monthly\":30, \"Quarterly\": 90, \"Semi-annually\": 180, \"Annually\":365}\n",
    "        DAYS = pf_rebal.get()\n",
    "        #print(rebalancing_days[pf_rebal.get()]) 30\n",
    "        \n",
    "        algo_name = pf_algo.get()\n",
    "        obj_name = pf_obj.get()\n",
    "        bench_name = pf_bench.get()\n",
    "        initial_balance = int(balance_space.get())\n",
    "        currency.Date = pd.to_datetime(currency.Date, utc = True)\n",
    "        \n",
    "        #print(algo_name, obj_name, bench_name, initial_balance, type(initial_balance)) [MVO] Mean-Variance Optimization  Max Sharpe KOSPI 1000000 <class 'str'>\n",
    "        \n",
    "        ## 02.portfolio part\n",
    "        if bench_name == \"KOSPI\":\n",
    "            bench_ret = fdr.DataReader('KS11', start_date)['Close']\n",
    "            bench_ret.index = pd.to_datetime(bench_ret.index, utc = True)\n",
    "            exchange = currency.loc[currency.Date.isin(bench_ret.index)]['Close']\n",
    "            exchange.index = bench_ret.index\n",
    "            bench_ret *= exchange\n",
    "            bench_ret.name = 'KOSPI'\n",
    "        \n",
    "        elif bench_name == \"S&P500\":\n",
    "            bench_ret = fdr.DataReader('US500', start_date)['Close']\n",
    "            bench_ret.index = pd.to_datetime(bench_ret.index, utc = True)\n",
    "            exchange = currency.loc[currency.Date.isin(bench_ret.index)]['Close']\n",
    "            exchange.index = bench_ret.index\n",
    "            bench_ret *= exchange\n",
    "            bench_ret.name = 'S&P500'\n",
    "\n",
    "        start_date = pd.to_datetime(start_date, utc = True)\n",
    "        \n",
    "        ## initial settings\n",
    "        total_amount = initial_balance\n",
    "        end_date = start_date + pd.Timedelta(days = rebalancing_days[DAYS])\n",
    "        re_date = start_date\n",
    "        utc_time = [pd.to_datetime(x, utc = True) for x in stock_df.Date]\n",
    "        stock_df.Date = utc_time\n",
    "\n",
    "        # make pf_positions\n",
    "        pf_positions = pd.DataFrame({x:[0] for x in stock_df.columns[1:]})\n",
    "        pf_positions['cash'] = initial_balance\n",
    "        pf_positions.index = [end_date - pd.Timedelta(days=1)]\n",
    "\n",
    "        # make pf_transactions\n",
    "        pf_transactions = pd.DataFrame({x:[0] for x in ['amount', 'order_id', 'price', 'sid', 'symbol', 'txn_dollars']})\n",
    "        pf_transactions.index = [end_date - pd.Timedelta(days=1)]\n",
    "\n",
    "        loop_time_list = [start_date]\n",
    "        weights_dict = {}\n",
    "\n",
    "        total_cnt = 0\n",
    "        \n",
    "        while True:\n",
    "            end_date = re_date + pd.Timedelta(days = rebalancing_days[DAYS])\n",
    "            #print(end_date)\n",
    "\n",
    "            ## end date 보정\n",
    "            if not end_date >= utc_time[-1]:\n",
    "                while True:\n",
    "                    if end_date not in list(stock_df.Date):\n",
    "                        end_date += pd.Timedelta(days = 1)\n",
    "                    elif end_date in list(stock_df.Date): \n",
    "                        break\n",
    "            else:\n",
    "                real_df = stock_df.loc[(stock_df.Date >= re_date) & (stock_df.Date < end_date)]\n",
    "                real_df_pct = real_df.iloc[:, 1:].pct_change().iloc[1:, :]\n",
    "\n",
    "                ## 0이 아닌 컬럼 선택\n",
    "                not_zero_idx = np.where(pf_positions.loc[re_date,:] != 0)[0]\n",
    "                select_col = list(pf_positions.columns[not_zero_idx])\n",
    "                select_col.remove(\"cash\")\n",
    "\n",
    "                ## 종목 변화 계산\n",
    "                temp_df = pd.DataFrame()\n",
    "                for col in select_col:\n",
    "                    initial_value = pf_positions.loc[re_date, col]\n",
    "                    temp_df[col] = cal_changes(initial_value, real_df_pct, col)\n",
    "\n",
    "                # temp_df date 중 추가할 부분만 선택\n",
    "                temp_df.index = real_df.Date\n",
    "                temp_df = temp_df.loc[temp_df.index > np.max(pf_positions.index)]\n",
    "\n",
    "                # pr positions 갱신\n",
    "                pf_positions = pf_positions.reset_index()\n",
    "                pf_positions = pf_positions.rename(columns={\"index\":\"Date\"})\n",
    "                temp_df = temp_df.reset_index()\n",
    "\n",
    "                on_list = ['Date']\n",
    "                on_list.extend(select_col)\n",
    "\n",
    "                pf_positions = pd.merge(pf_positions, temp_df, on = on_list, how = \"outer\")\n",
    "\n",
    "                pf_positions.index = pf_positions.Date\n",
    "                pf_positions = pf_positions.iloc[:, 1:]\n",
    "\n",
    "                # cash 마지막 값 복붙\n",
    "                pf_positions.loc[pf_positions.index > re_date, 'cash'] = pf_positions.loc[re_date, 'cash']\n",
    "                pf_positions.replace(np.NaN, 0, inplace = True)\n",
    "                \n",
    "                # get final weights\n",
    "                df = stock_df.loc[(stock_df.Date >= start_date) & (stock_df.Date < end_date)]\n",
    "                df = df.loc[:, ~df.columns.isin(['Date'])]\n",
    "                df = df.iloc[:, np.where(df.isna().sum() / df.shape[0] != 1)[0]]\n",
    "                if algo_name == \"[MVO] Mean-Variance Optimization\":\n",
    "                    ef = EfficientFrontier(mean_return, cs_01)\n",
    "                    weights = obj_functions(ef, obj_name)\n",
    "\n",
    "                elif algo_name == \"[HRP] Hierarchical Risk Parity\":\n",
    "                    rp = pypfopt.hierarchical_portfolio.HRPOpt(price_return, cs_01)\n",
    "                    weights = rp.optimize()\n",
    "\n",
    "                elif algo_name == \"[CLA] The Critical Line Algorithm\":\n",
    "                    cla = CLA(mean_return, cs_01, weight_bounds=(0, 1))\n",
    "                    weights = obj_functions(cla, obj_name)\n",
    "                final_weights = weights\n",
    "                break\n",
    "\n",
    "            loop_time_list.append(end_date)\n",
    "            df = stock_df.loc[(stock_df.Date >= start_date) & (stock_df.Date < end_date)]\n",
    "            df = df.loc[:, ~df.columns.isin(['Date'])]\n",
    "            df = df.iloc[:, np.where(df.isna().sum() / df.shape[0] != 1)[0]]\n",
    "            \n",
    "            # 최적화 포트 계산         \n",
    "            # get return\n",
    "            #capm_return = get_return(df, 'capm')\n",
    "            price_return = get_return(df, 'price')\n",
    "            mean_return = get_return(df, 'mean')\n",
    "            #ema_return = get_return(df, 'ema')\n",
    "        \n",
    "            # get cov\n",
    "            cs_01 = get_cov(df, opt = 'CovarianceShrinkage-01')\n",
    "            #cs_02 = get_cov(df, opt = 'CovarianceShrinkage-02')\n",
    "            #cs_03 = get_cov(df, opt = 'CovarianceShrinkage-03')\n",
    "            #S_exp = get_cov(df, opt = 'exp_cov')\n",
    "            #S_semi = get_cov(df, opt = 'semicovariance')\n",
    "            \n",
    "            try:\n",
    "                if algo_name == \"[MVO] Mean-Variance Optimization\":\n",
    "                    ef = EfficientFrontier(mean_return, cs_01)\n",
    "                    weights = obj_functions(ef, obj_name)\n",
    "\n",
    "                elif algo_name == \"[HRP] Hierarchical Risk Parity\":\n",
    "                    rp = pypfopt.hierarchical_portfolio.HRPOpt(price_return, cs_01)\n",
    "                    weights = rp.optimize()\n",
    "\n",
    "                elif algo_name == \"[CLA] The Critical Line Algorithm\":\n",
    "                    cla = CLA(mean_return, cs_01, weight_bounds=(0, 1))\n",
    "                    weights = obj_functions(cla, obj_name)\n",
    "            except:\n",
    "                msgbox.showerror(\"최적화 에러\", \"다른 Optimizer 혹은 Objective를 선택하세요.\")\n",
    "                complete = False\n",
    "                break\n",
    "                \n",
    "            weights_dict[end_date] = weights\n",
    "\n",
    "            ### 모든 포지션 청산\n",
    "            ## position 갱신\n",
    "            if total_cnt > 0:\n",
    "                real_df = stock_df.loc[(stock_df.Date >= re_date) & (stock_df.Date < end_date)]\n",
    "                real_df_pct = real_df.iloc[:, 1:].pct_change().iloc[1:, :]\n",
    "\n",
    "                ## 0이 아닌 컬럼 선택\n",
    "                not_zero_idx = np.where(pf_positions.loc[re_date,:] != 0)[0]\n",
    "                select_col = list(pf_positions.columns[not_zero_idx])\n",
    "                select_col.remove(\"cash\")\n",
    "\n",
    "                ## 종목 변화 계산\n",
    "                temp_df = pd.DataFrame()\n",
    "                for col in select_col:\n",
    "                    initial_value = pf_positions.loc[re_date, col]\n",
    "                    temp_df[col] = cal_changes(initial_value, real_df_pct, col)\n",
    "\n",
    "                # temp_df date 중 추가할 부분만 선택\n",
    "                temp_df.index = real_df.Date\n",
    "                temp_df = temp_df.loc[temp_df.index > np.max(pf_positions.index)]\n",
    "\n",
    "                # pr positions 갱신\n",
    "                pf_positions = pf_positions.reset_index()\n",
    "                pf_positions = pf_positions.rename(columns={\"index\":\"Date\"})\n",
    "                temp_df = temp_df.reset_index()\n",
    "\n",
    "                on_list = ['Date']\n",
    "                on_list.extend(select_col)\n",
    "\n",
    "                pf_positions = pd.merge(pf_positions, temp_df, on = on_list, how = \"outer\")\n",
    "\n",
    "                pf_positions.index = pf_positions.Date\n",
    "                pf_positions = pf_positions.iloc[:, 1:]\n",
    "\n",
    "                # cash 마지막 값 복붙\n",
    "                pf_positions.loc[pf_positions.index > re_date, 'cash'] = pf_positions.loc[re_date, 'cash']\n",
    "                pf_positions.replace(np.NaN, 0, inplace = True)\n",
    "\n",
    "                append_positions = deepcopy(pf_positions.tail(1))\n",
    "                append_positions.index = [end_date]\n",
    "\n",
    "                append_transactions = deepcopy(pf_transactions.tail(1))\n",
    "                append_transactions.index = [end_date]\n",
    "\n",
    "                ## 마지막 total money 계산\n",
    "                total_amount = pf_positions.iloc[:, not_zero_idx].tail(1).sum(axis = 1).values[0]\n",
    "\n",
    "                ## 청산 코드\n",
    "                ratio = -1\n",
    "                for name in select_col:\n",
    "                    get_values = get_price(stock_df, end_date, name)\n",
    "\n",
    "                    # append_transactions\n",
    "                    tot_amts = pf_transactions.loc[pf_transactions.sid == name].amount.sum()\n",
    "\n",
    "                    # transactions\n",
    "                    append_transactions['amount'] = int(tot_amts * ratio)\n",
    "                    append_transactions['order_id'] = str(total_cnt)\n",
    "                    append_transactions['price'] = get_values\n",
    "                    append_transactions['sid'] = name\n",
    "                    append_transactions['symbol'] = name\n",
    "                    append_transactions['txn_dollars'] = -(int(tot_amts * ratio) * get_values)\n",
    "\n",
    "                    pf_transactions = pd.concat([pf_transactions, append_transactions])\n",
    "\n",
    "                    # positions\n",
    "                    append_positions.loc[:, 'cash'] -= append_positions.loc[end_date, name] * ratio\n",
    "                    append_positions.loc[:, name] += append_positions.loc[end_date, name] * ratio\n",
    "\n",
    "                    total_cnt += 1\n",
    "\n",
    "                if end_date >= utc_time[-1]:\n",
    "                    break\n",
    "\n",
    "            else:\n",
    "                append_positions = deepcopy(pf_positions.tail(1))\n",
    "                append_positions.index = [end_date]\n",
    "\n",
    "                append_transactions = deepcopy(pf_transactions.tail(1))\n",
    "                append_transactions.index = [end_date]\n",
    "\n",
    "            ## 구매 코드\n",
    "            buy_dict = {x:np.round(y, 4) for x,y in zip(weights.keys(), weights.values())}\n",
    "\n",
    "            # 구매할 종목 및 금액\n",
    "            buy_list = []\n",
    "            buy_amt = []\n",
    "\n",
    "            for st_name, percent in weights.items():\n",
    "                percent = np.round(percent, 4)\n",
    "                if percent > 0:\n",
    "                    buy_amt.append(np.round(total_amount * percent, 3))\n",
    "                    buy_list.append(st_name)\n",
    "\n",
    "            buy_cnt = 0\n",
    "            for name, amt in zip(buy_list, buy_amt):\n",
    "                get_values = get_price(stock_df, end_date, name)\n",
    "                amount = int(buy_amt[buy_cnt] / get_values)\n",
    "                total_amt = get_values * amount\n",
    "                append_positions[name] = total_amt\n",
    "                append_positions['cash'] -= total_amt\n",
    "\n",
    "                # transactions\n",
    "                append_transactions['amount'] = amount\n",
    "                append_transactions['order_id'] = str(total_cnt)\n",
    "                append_transactions['price'] = get_values\n",
    "                append_transactions['sid'] = name\n",
    "                append_transactions['symbol'] = name\n",
    "                append_transactions['txn_dollars'] = -total_amt\n",
    "\n",
    "                pf_transactions = pd.concat([pf_transactions, append_transactions])\n",
    "\n",
    "                buy_cnt += 1\n",
    "                total_cnt += 1\n",
    "\n",
    "            pf_positions = pd.concat([pf_positions, append_positions])\n",
    "\n",
    "            # 날짜 업데이트\n",
    "            re_date = end_date\n",
    "            before_date = pf_positions.tail(1).index[0]\n",
    "            ## end of while\n",
    "            \n",
    "        pf_returns = pf_positions.sum(axis = 1).pct_change().iloc[1:]\n",
    "        \n",
    "        ## benchmark\n",
    "        bench_ret = bench_ret.loc[bench_ret.index.isin(pf_returns.index)]\n",
    "        \n",
    "        save_img_path = data_path + \"\\\\imgs\\\\\"\n",
    "\n",
    "        if not os.path.isdir(save_img_path):\n",
    "            os.mkdir(save_img_path)\n",
    "        \n",
    "        ## save fig\n",
    "        plot_abount_returns(pf_returns, pf_positions, bench_ret, save_img_path, bench_name, inches = (12, 8))\n",
    "        \n",
    "        ## pie chart\n",
    "        weights_df = pd.DataFrame.from_dict(final_weights, orient='index', columns=['allocations'])\n",
    "        weights_df = weights_df.loc[weights_df.allocations != 0]\n",
    "        plot_pie(weights_df, save_img_path)\n",
    "        \n",
    "        ## save markdown\n",
    "        mdFile = MdUtils(file_name='Portfolio Report',title='HUG-Portfolio Reports')\n",
    "        mdFile.create_md_file()\n",
    "        mdFile.new_line(\"<br>\")\n",
    "\n",
    "        mdFile.new_header(level=1, title='')\n",
    "        start_str = \"{year}.{month}.{day}\".format(year = start_date.year, month = start_date.month, day = start_date.day)\n",
    "        now_str = \"{year}.{month}.{day}\".format(year = datetime.now().year, month = datetime.now().month, day = datetime.now().day)\n",
    "        mdFile.new_header(level=2, title='01. Portfolio Allocations ({}~{})'.format(start_str, now_str))\n",
    "        mdFile.new_line(\"<br>\")\n",
    "\n",
    "        mdFile.new_line(\"최적화된 포트폴리오의 샤프 비율, 시장 베타, 최대 손실폭은 다음과 같다.\",bold_italics_code='bold')\n",
    "        mdFile.new_line(\"<br>\")\n",
    "        mdFile.new_line(\"1. The Sharpe Ratio of the backtest is (샤프 비율): {}\".format(np.round(empyrical.sharpe_ratio(pf_returns), 4)))\n",
    "        mdFile.new_line(\"2. The market beta of the backtest is (시장 베타): {}\".format(np.round(empyrical.beta(pf_returns, bench_ret.pct_change()),4)))\n",
    "        mdFile.new_line(\"3. The maxmimum drawdown of the backtest is (최대 손실폭): {}\".format(np.round(empyrical.max_drawdown(pf_returns), 4)))\n",
    "\n",
    "        mdFile.new_line(\"<br>\")\n",
    "        mdFile.new_line(\"현재 시점으로 보유 종목의 최적 배분은 다음과 같다.\",bold_italics_code='bold')\n",
    "        mdFile.new_header(level=2, title='')\n",
    "\n",
    "        weights_df = pd.DataFrame.from_dict(weights, orient='index', columns=['Allocations'])\n",
    "        weights_df = weights_df.loc[weights_df.Allocations != 0]\n",
    "        weights_df['Balance'] = np.array(pf_positions.tail(1).loc[:, weights_df.index])[0]\n",
    "        append_weights = pd.DataFrame({\"Allocations\":[0.0], \"Balance\": [np.array(pf_positions.tail(1)['cash'])[0]]}, index = ['현금'])\n",
    "        weights_df = pd.concat([weights_df, append_weights])\n",
    "        weights_df['Allocations'] = [str(np.round(x,4)) for x in weights_df['Allocations']]\n",
    "        weights_df['Balance'] = [str(np.int(x)) for x in weights_df['Balance']]\n",
    "\n",
    "        mdFile.write(weights_df.to_markdown() + \"\\n\")\n",
    "\n",
    "        mdFile.new_header(level=3, title='')\n",
    "        mdFile.new_header(level=4, title='[표 1] 최적 포트폴리오 배분')\n",
    "        mdFile.new_line(\"<br>\")\n",
    "\n",
    "        mdFile.new_line(mdFile.new_inline_image(text='Portfolio Allocations', path='./datasets/imgs/Portfolio Allocations.png'))\n",
    "\n",
    "        mdFile.new_header(level=4, title='[그림 1] 최적 포트폴리오 배분 파이 차트')\n",
    "        mdFile.new_line(\"<br>\")\n",
    "\n",
    "        mdFile.new_header(level=2, title='02. 포트폴리오 성과 통계량 요약')\n",
    "\n",
    "        mdFile.new_line(\"<br>\")\n",
    "        #mdFile.new_line(\"포트폴리오 전체 기간에 대한 측정 항목 및 통계량은 다음과 같다.\", bold_italics_code='bold')\n",
    "        mdFile.new_line(\"포트폴리오 전체 기간에 대한 측정 항목 및 통계량은 다음과 같다.\")\n",
    "\n",
    "        mdFile.new_header(level=2, title='')\n",
    "        port_summary = get_perf_stats(pf_returns)\n",
    "        port_summary.columns = ['성과 통계량']\n",
    "        temp_idx = ['연간 수익률', '누적 수익률', '연간 변동성', '샤프 비율', '칼마 비율', '안정성', '최대 손실 폭', '오메가 비율', '솔티노 비율', '왜도', '첨도', '테일 비율', '일별 VaR']\n",
    "        port_summary.index = [x+\" ({})\".format(y) for x,y in zip(temp_idx, port_summary.index)]\n",
    "        mdFile.write(port_summary.to_markdown() + \"\\n\")\n",
    "\n",
    "        mdFile.new_header(level=3, title='')\n",
    "        mdFile.new_header(level=4, title='[표 2] 포트폴리오 성과 통계표')\n",
    "        mdFile.new_line(\"<br>\")\n",
    "\n",
    "        mdFile.new_line(mdFile.new_inline_image(text='Portfolio Summary', path='./datasets/imgs/Portfolio Summary.png'))\n",
    "        mdFile.new_header(level=4, title='[그림 2] 포트폴리오 성과 통계 도표')\n",
    "\n",
    "        mdFile.new_line(\"<br>\")\n",
    "        mdFile.new_header(level=2, title='03. 포트폴리오 백테스팅 결과')\n",
    "        mdFile.new_header(level=3, title='03.1 포트폴리오 Growth & Returns')\n",
    "        mdFile.new_line(\"<br>\")\n",
    "        mdFile.new_line(\"벤치마크 대비 포트폴리오의 기간 내 성과는 다음과 같다.\")\n",
    "        mdFile.new_header(level=2, title='')\n",
    "        mdFile.new_header(level=3, title='')\n",
    "\n",
    "        mdFile.new_line(mdFile.new_inline_image(text='Growth & Return', path='./datasets/imgs/Growth & Return.png'))\n",
    "        mdFile.new_header(level=4, title='[그림 3] 포트폴리오의 기간 내 Growth & Returns')\n",
    "\n",
    "        mdFile.new_line(\"<br>\")\n",
    "        mdFile.new_header(level=3, title='03.2 포트폴리오 월/연도별 Returns')\n",
    "        mdFile.new_line(\"<br>\")\n",
    "        mdFile.new_line(\"포트폴리오의 연도별 Returns는 다음과 같다.\")\n",
    "\n",
    "        mdFile.new_header(level=3, title='')\n",
    "        pf_year = pd.DataFrame(pf.timeseries.aggregate_returns(pf_returns, 'yearly'))\n",
    "        pf_year.index.name = ''\n",
    "        pf_year.columns = ['Return']\n",
    "        mdFile.write(pf_year.to_markdown() + \"\\n\")\n",
    "        mdFile.new_header(level=4, title='[표 3] 연도별 Returns')\n",
    "\n",
    "        mdFile.new_line(\"<br>\")\n",
    "        mdFile.new_line(\"포트폴리오의 연도별, 월별 Returns를 도식화하면 그림 4와 같으며 좌측 상단부터 시계방향으로 설명하면 다음과 같다.   \", bold_italics_code='bold')\n",
    "        mdFile.new_line(\"<br>\")\n",
    "        mdFile.new_line(\"1. 연도별 Returns\")\n",
    "        mdFile.new_line(\"2. 월별 Returns의 분포\")\n",
    "        mdFile.new_line(\"3. 연도-월별 Returns의 막대 그래프\")\n",
    "        mdFile.new_line(\"4. 연도-월별 Returns의 히트맵\")\n",
    "        mdFile.new_line(\" \")\n",
    "\n",
    "        mdFile.new_line(mdFile.new_inline_image(text='Annual Returns', path='./datasets/imgs/Monthly & Annualy Returns.png'))\n",
    "        mdFile.new_header(level=4, title='[그림 4] 월 & 연도별 Returns 도표')\n",
    "        mdFile.new_line(\"<br>\")\n",
    "\n",
    "\n",
    "\n",
    "        mdFile.new_line(\"<br>\")\n",
    "        mdFile.new_header(level=3, title='03.3 포트폴리오 하락 기간과 팩터 노출')\n",
    "        mdFile.new_line(\"<br>\")\n",
    "        mdFile.new_line(\"해당 포트의 주요 하락 기간은 다음과 같다.\")\n",
    "\n",
    "        mdFile.new_header(level=3, title='')\n",
    "        port_ddw = pf.timeseries.gen_drawdown_table(pf_returns, top = 5)\n",
    "        mdFile.write(port_ddw.to_markdown() + \"\\n\")\n",
    "        mdFile.new_header(level=4, title='[표 4] Top 5 하락 기간')\n",
    "\n",
    "        mdFile.new_line(\"<br>\")\n",
    "        mdFile.new_line(\"포트폴리오의 연도별, 월별 Returns를 도식화하면 그림 4와 같으며 좌측 상단부터 시계방향으로 설명하면 다음과 같다.   \", bold_italics_code='bold')\n",
    "        mdFile.new_line(\"<br>\")\n",
    "        mdFile.new_line(\"1. Top 5 손실 기간 \")\n",
    "        mdFile.new_line(\"2. 롤링 포트폴리오 베타\")\n",
    "        mdFile.new_line(\"3. Underwater Plot\")\n",
    "        mdFile.new_line(\"4. 롤링 샤프 비율 (6개월)\")\n",
    "        mdFile.new_line(\" \")\n",
    "\n",
    "        mdFile.new_line(mdFile.new_inline_image(text='Factor & Drawdown', path='./datasets/imgs/Factor & Drawdown.png'))\n",
    "        mdFile.new_header(level=4, title='[그림 5] 시간 경과에 따른 하락 기간 및 팩터 노출 그래프')\n",
    "        mdFile.new_line(\"<br>\")\n",
    "        \n",
    "        mdFile.create_md_file()\n",
    "k\n",
    "        markdown.markdownFromFile(\n",
    "            input='Portfolio Report.md',\n",
    "            output='Portfolio Report.html',\n",
    "            extensions=['markdown.extensions.tables'],\n",
    "            encoding='utf8'\n",
    "        )\n",
    "        if complete :\n",
    "            msgbox.showinfo(\"알림\", \"작업이 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbc6f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48aa0030",
   "metadata": {},
   "source": [
    "* layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2b57b92e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "rebalancing_days = {\"Monthly\":30, \"Quarterly\": 90, \"Semi-annually\": 180, \"Annually\":365}\n",
    "\n",
    "root = Tk()\n",
    "root.title(\"HUG-Portfolio Analysis\")\n",
    "root.option_add(\"*tearOff\", False)\n",
    "\n",
    "# Create a style\n",
    "style = ttk.Style(root)\n",
    "\n",
    "root.tk.call(\"source\", \"./add/forest-light.tcl\")\n",
    "style.theme_use(\"forest-light\")\n",
    "root.update_idletasks()\n",
    "\n",
    "# 파일 프레임 (파일 추가, 선택 삭제)\n",
    "file_frame = ttk.LabelFrame(root, text = \"WINK 1171 or WINK 6002\")\n",
    "file_frame.pack(fill=\"x\", padx=5, pady=5) # 간격 띄우기\n",
    "\n",
    "btn_frame = Frame(file_frame)\n",
    "btn_frame.pack(side = \"right\")\n",
    "\n",
    "data_space = ttk.Entry(file_frame, width = 85)\n",
    "data_space.pack()\n",
    "\n",
    "# 옵션 프레임\n",
    "frame_option = ttk.Frame(root)\n",
    "frame_option.pack(padx=5, pady=5, ipady=5)\n",
    "\n",
    "notebook = ttk.Notebook(frame_option)\n",
    "pf_options = ttk.Frame(notebook)\n",
    "\n",
    "pf_left = ttk.Frame(pf_options)\n",
    "pf_right = ttk.Frame(pf_options)\n",
    "\n",
    "pf_left.pack(side = \"left\")\n",
    "pf_right.pack(side = \"right\")\n",
    "\n",
    "# 1. rebalancing settings\n",
    "pf_cate_label = Label(pf_left, text=\"Rebalancing\", width=15)\n",
    "pf_cate_label.grid(row = 0, column=0, padx=2, pady=5)\n",
    "\n",
    "opt_rebal_cate = list(rebalancing_days.keys())\n",
    "pf_rebal = ttk.Combobox(pf_left, state=\"readonly\", values=opt_rebal_cate, width=20)\n",
    "pf_rebal.current(0)\n",
    "pf_rebal.grid(row = 0, column=1, padx=2, pady=5)\n",
    "\n",
    "# 2. optimization methods 선택\n",
    "pf_optim_label = Label(pf_left, text=\"Optimizers\", width=15)\n",
    "pf_optim_label.grid(row = 1, column=0, padx=2, pady=5)\n",
    "\n",
    "opt_pf_algo = ['[MVO] Mean-Variance Optimization', '[HRP] Hierarchical Risk Parity', '[CLA] The Critical Line Algorithm']\n",
    "pf_algo = ttk.Combobox(pf_left, state=\"readonly\", values=opt_pf_algo, width=20)\n",
    "pf_algo.current(0)\n",
    "pf_algo.grid(row = 1, column=1, padx=2, pady=5)\n",
    "\n",
    "# 3. Objectvie function 선택\n",
    "pf_obj_label = Label(pf_left, text=\"Objective\", width=15)\n",
    "pf_obj_label.grid(row = 2, column=0, padx=2, pady=5)\n",
    "\n",
    "obj_label = ['Max Sharpe', 'Min Volatility']\n",
    "pf_obj = ttk.Combobox(pf_left, state=\"readonly\", values=obj_label, width=20)\n",
    "pf_obj.current(0)\n",
    "pf_obj.grid(row = 2, column=1, padx=2, pady=5)\n",
    "\n",
    "# 4. Start yaer\n",
    "pf_year_label = Label(pf_right, text=\"Start Year\", width=15)\n",
    "pf_year_label.grid(row = 0, column=0, padx=2, pady=5)\n",
    "\n",
    "opt_start_year = [x for x in range(1990, 2023)]\n",
    "pf_year = ttk.Combobox(pf_right, state=\"readonly\", values=opt_start_year, width=20)\n",
    "pf_year.current(0)\n",
    "pf_year.grid(row = 0, column=1, padx=2, pady=5)\n",
    "\n",
    "# 5. benchmark\n",
    "pf_bench_label = Label(pf_right, text=\"Benchmark\", width=15)\n",
    "pf_bench_label.grid(row=1, column=0, padx=5, pady=5)\n",
    "\n",
    "opt_bench = ['KOSPI', 'S&P500']\n",
    "pf_bench = ttk.Combobox(pf_right, state=\"readonly\", values=opt_bench, width=20)\n",
    "pf_bench.current(0)\n",
    "pf_bench.grid(row = 1, column=1, padx=2, pady=5)\n",
    "\n",
    "# 6. initial balance\n",
    "pf_balance_label = Label(pf_right, text=\"Initial Balance\", width=15)\n",
    "pf_balance_label.grid(row=2, column=0, padx=2, pady=5)\n",
    "\n",
    "balance_space = ttk.Entry(pf_right, width = 23)\n",
    "balance_space.grid(row=2, column=1, padx=2, pady=5)\n",
    "\n",
    "notebook.add(pf_options, text = \"Portfolio Settings\")\n",
    "notebook.pack()\n",
    "\n",
    "# 실행 프레임\n",
    "frame_run = Frame(root)\n",
    "frame_run.pack(fill=\"x\", padx=5, pady=5)\n",
    "\n",
    "btn_close = ttk.Button(frame_run, text=\"Close\", width=12, command=root.quit)\n",
    "btn_close.pack(side=\"right\", padx=5, pady=5)\n",
    "\n",
    "btn_start = ttk.Button(frame_run, text=\"Start\", width=12, command = main_functions)\n",
    "btn_start.pack(side=\"right\", padx=5, pady=5)\n",
    "\n",
    "root.resizable(True, True)\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998f0bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
